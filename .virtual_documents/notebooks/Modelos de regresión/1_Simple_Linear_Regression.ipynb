


get_ipython().run_line_magic("load_ext", " kedro.ipython ")


catalog.keys()


catalog.load("model_input_table")


df_FIFA = catalog.load("model_input_table")





# -- Tratamiento de datos --
import numpy as np
import pandas as pd

# -- Gráficos -- 
import seaborn as sns
from matplotlib import style
import matplotlib.pyplot as plt

# -- Procesado y modelado --
from sklearn.linear_model import LinearRegression 
from sklearn.model_selection import train_test_split

# -- Metricas --
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error 
from sklearn.metrics import mean_absolute_error

# -- GridSearchCV -- 
from sklearn.model_selection import GridSearchCV


df_FIFA['Value_num'] = np.log1p(df_FIFA['Value_num'])  


numeric_df = df_FIFA.select_dtypes(include=np.number)

correlation_matrix = numeric_df.corr()

plt.figure(figsize=(30, 20))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numeric Columns')
plt.show()








X = df_FIFA[["Overall"]] 
y = df_FIFA['Value_num']





X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle = True)

print("Datos de entrenamiento: ",X_train.shape)
print("Datos de prueba: ",X_test.shape)





modelo = LinearRegression( fit_intercept=True,  # que calcule la ordenada al origen
    copy_X=True,         # no modifica tu DataFrame original
    n_jobs=None,         # usa un CPU
    positive=False)

modelo.fit(X_train, y_train)





#En otros casos se usa el nombre de y_hat para identificar las predicciones 
y_pred = modelo.predict(X_test)





mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Métricas de evaluación
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Mostrar resultados
print("-- Métricas de Evaluación del Modelo --")
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)
print(f"R² (Variance score): {r2:.2f}")





plt.figure(figsize=(8,6))

#Alpha: simplemente trasparencia de los datos

plt.scatter(X_test, y_test, color='green', alpha=0.6, label='Datos reales')

plt.plot(X_test, y_pred, color='yellow', alpha=0.9, label='Línea de regresión', linewidth=2)

plt.xlabel('Overall')
plt.ylabel('Value_num')
plt.title('Regresión Lineal Simple con colores pastel')
plt.legend()
plt.show()





modelo = LinearRegression()

param_grid = {
    'fit_intercept': [True, False],
    'copy_X': [True, False],
    'n_jobs': [None, -1] # Added 'n_jobs' as a valid parameter for potential performance improvement
}

# Crear el GridSearchCV
# cv: número de folds para la validación cruzada. 5 es un valor común.
# Added 'n_jobs=-1' to GridSearchCV for parallel processing
grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, 
                           cv=5,
                           scoring='r2',
                           n_jobs=-1
                          )

# Entrenar el GridSearchCV en los datos de entrenamiento
grid_search.fit(X_train, y_train)

# Obtener los mejores parámetros encontrados por GridSearchCV
best_params = grid_search.best_params_

# Obtener el mejor modelo entrenado
best_model = grid_search.best_estimator_

print(f"Mejores parámetros encontrados por GridSearchCV: {best_params}")

# Predecir con el mejor modelo
y_pred_best = best_model.predict(X_test)

# Calcular métricas con el mejor modelo
mse_best = mean_squared_error(y_test, y_pred_best)
mae_best = mean_absolute_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)
rmse_best = np.sqrt(mse_best)

# Imprimir resultados del mejor modelo
print("\nMétricas del Modelo de Regresión Lineal con 'mejores parámetros':")
print(f"Mean Squared Error (MSE): {mse_best}")
print(f"Mean Absolute Error (MAE): {mae_best}")
print(f"Root Mean Squared Error (RMSE): {rmse_best}")
print(f"R2 Score: {r2_best}")


plt.figure(figsize=(8,6))

plt.scatter(X_test, y_test, color='green', alpha=0.6, label='Datos reales')
plt.plot(X_test, y_pred, color='red', alpha=0.9, label='Línea de regresión', linewidth=2)

plt.xlabel('Overall')
plt.ylabel('Value_num')
plt.title('Regresión Lineal Simple con colores pastel')
plt.legend()
plt.show()



