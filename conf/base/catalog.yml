# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

# Aqui podemos definir estructuras donde
# nosotros podemos definir nuestros datasets
# usando una sintaxis simple de YAML.
# Con esto podemos llamar los datasets
# desde cualquier parte del proyecto.

DataSetFIFA22:
  type: pandas.CSVDataset
  filepath: data/01_raw/FIFA22_official_data.csv
  load_args:
    sep: ","
    decimal: "."
  save_args:
    index: False  
 
DataSetFIFA21:
  type: pandas.CSVDataset
  filepath: data/01_raw/FIFA21_official_data.csv
  load_args:
    sep: ","
    decimal: "."
  save_args:
    index: False

DataSetFIFA20:
  type: pandas.CSVDataset
  filepath: data/01_raw/FIFA20_official_data.csv
  load_args:
    sep: ","
    decimal: "."
  save_args:
    index: False

# ============================
# Etapa de procesamiento de datos
# ============================

preprocess_fifa_22:
  type: pandas.ParquetDataset # Ahora definimos que la salida sea tipo parquet para que sea mas liviano 
  filepath: data/02_intermediate/preprocess_fifa_22.parquet     

preprocess_fifa_21:
  type: pandas.ParquetDataset # Ahora definimos que la salida sea tipo parquet para que sea mas liviano 
  filepath: data/02_intermediate/preprocess_fifa_21.parquet     

preprocess_fifa_20:
  type: pandas.ParquetDataset # Ahora definimos que la salida sea tipo parquet para que sea mas liviano 
  filepath: data/02_intermediate/preprocess_fifa_20.parquet 


FIFA22_processed_con_transformacion_columns:
  type: pandas.ParquetDataset 
  filepath: data/02_intermediate/FIFA22_processed_con_transformacion_columns.parquet  

FIFA21_processed_con_transformacion_columns:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/FIFA21_processed_con_transformacion_columns.parquet

FIFA20_processed_con_transformacion_columns:
  type: pandas.ParquetDataset 
  filepath: data/02_intermediate/FIFA20_processed_con_transformacion_columns.parquet  

# ============================
# Union de datasets y creacion de dataset de entrada para los modelos (Model input table)
# ============================

# OJO, al pasar la evaluacion 3 con las tecnicas de modelo no supervizados, crearemos un nuevo dataset limpio, asi que ahi veremos si se elimina o se mantiene
# ¿Es necesario tenerlo ahora? [] <-- si es un no, entonces no se elimina para tomarlo en cuenta en futuros proyecto.

model_input_table:
  type: pandas.ParquetDataset 
  filepath: data/03_primary/model_input_table.parquet #lo definimos en 03_primary porque ya tendremos nuestros datasets unidos

# ============================
# Entradas de para los modelos, train y test.
# ============================

#TRAIN TEST REGRESION

X_train_regression:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train_regression.csv
  save_args:
    index: False

X_test_regression:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test_regression.csv
  save_args:
    index: False

y_test_regression:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test_regression.csv
  save_args:
    index: False

# TRAIN TEST CLASIFICACION

# -- Features de entrenamiento y prueba --

X_train_class:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train_class.csv
  save_args:
    index: False

X_test_class:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test_class.csv
  save_args:
    index: False

# -- Target de entrenamiento y prueba --

y_train_class:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_train_class.csv
  save_args:
    index: False

y_test_class:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test_class.csv
  save_args:
    index: False

# ============================
# Etapa de  modelodo
# ============================

# Ahora que en el primero nodo del pipeline de modelado regression_models
# No tiene una salida de tipo pandas porque es un diccionario
# Entonces definimos un nuevo dataset de tipo PickleDataset. 

# ============================
# GridSearchCV modelo
# ============================

# versioned: true para versionar los modelos o guardarlos con versiones

# Salidas de los modelos de regresion 

grid_linear_model:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_linear_model.pkl
  versioned: true

grid_linear_multiple_model:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_linear_multiple_model.pkl
  versioned: true

grid_svr_model:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_svr_model.pkl
  versioned: true

grid_decision_tree_model:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_decision_tree_model.pkl
  versioned: true

grid_randomforest_model:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_randomforest_model.pkl
  versioned: true

# Salidas de los modelos entrenados de clasificación

grid_logistic_model_classification:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_logistic_model_classification.pkl
  versioned: true

grid_knn_model_classification:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_knn_model_classification.pkl
  versioned: true

grind_svc_cv_model_classification:
  type: pickle.PickleDataset
  filepath: data/06_models/grind_svc_cv_model_classification.pkl
  versioned: true

grid_decision_tree_model_classification:
  type: pickle.PickleDataset
  filepath: data/06_models/grid_decision_tree_model_classification.pkl  
  versioned: true

grid_random_forest_model_classification:  
  type: pickle.PickleDataset 
  filepath: data/06_models/grid_random_forest_model_classification.pkl
  versioned: true

# ============================
# Salidas de las predicciones de los modelos, para luego generar los reportes.
# En 07_model_output/

# Se guardan los Outputs del modelo
# No el modelo en sí.

# predictions_classification.parquet
# predictions_regression.parquet
# evaluation_metrics_classification.json
# evaluation_metrics_regression.json
# confusion_matrix.csv

# ============================
# Predicciónes 
# PD: lo habiamos eliminado y sus pipelines, pero el profe nos dice que (si aplica)
# Por lo que se vuelve a agregar, pero ahora con un nuevo formato, en vez de parquet, csv, para que sea mas facil de leer y generar los reportes.
# #en 07_model_output/ guardaremos las predicciones de los modelos, tanto de regresion como de clasificacion, para luego generar los reportes.

# ============================
#y_pred_linear.csv
#y_pred_rf.csv

# ============================
# Predicciones de regresion 

# y_nombre_modelo = y_pred
# ============================

y_pred_linear_regression:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_linear_regression.csv

y_pred_linear_multiple_regression:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_linear_multiple_regression.csv
  
y_pred_svr:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_svr.csv

y_pred_decision_tree_regression:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_decision_tree_regression.csv

y_pred_random_forest_regression:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_random_forest_regression.csv

# ============================
# Predicciones de clasificación
# ============================

y_pred_logistic_classification:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_logistic_classification.csv

y_pred_knn_classification:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_knn_classification.csv

y_pred_svc:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_svc.csv

y_pred_decision_tree_classification:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_decision_tree_classification.csv

y_pred_random_forest_classification:
  type: pandas.CSVDataset
  filepath: data/07_model_output/y_pred_random_forest_classification.csv

# ============================
# Metricas regresion
# ============================

metrics_linear_simple_regression:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_regression/metrics_linear_simple_regression.csv
  versioned: true

metrics_linear_multiple_regression:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_regression/metrics_linear_multiple_regression.csv
  versioned: true

metrics_svr:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_regression/metrics_svr.csv
  versioned: true

metrics_decision_tree_regression:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_regression/metrics_decision_tree_regression.csv
  versioned: true

metrics_random_forest_regression:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_regression/metrics_random_forest_regression.csv
  versioned: true

# ============================
# Metricas clasificación
# ============================

metrics_logistic:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_classification/logistic.csv
  versioned: true

metrics_knn_classification:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_classification/knn.csv
  versioned: true

metrics_svc:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_classification/svc.csv
  versioned: true

metrics_decision_tree_classification:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_classification/decision_tree.csv
  versioned: true

metrics_random_forest_classification:
  type: pandas.CSVDataset
  filepath: data/08_reporting/metrics_classification/random_forest.csv
  versioned: true

# ============================
# Reportes de regresion
# ============================

# Para report utilizar la libreria plotlib al utilizar Kedro viz
# ============================
# Esta es una version anterior de como de guardaban los reportes. Estos reportes en realidad eran metricas,
# entonces se guardaran como metricas en vez de reportes. Por lo que se creo otra carpeta raiz.
# Estas evaluaciones se generan en el pipeline de class_models y regression_models, y se guardan en la carpeta de reporting.

# report_linear_simple_regression:

report_linear_simple_pred_vs_real:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_simple/pred_vs_real.png
  versioned: true

report_linear_simple_residual_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_simple/residual_plot.png
  versioned: true

report_linear_simple_qq_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_simple/qq_plot.png
  versioned: true


# report_linear_multiple_regression:

report_linear_multiple_pred_vs_real:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_multiple/pred_vs_real.png
  versioned: true

report_linear_multiple_residual_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_multiple/residual_plot.png
  versioned: true

report_linear_multiple_qq_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/linear_multiple/qq_plot.png
  versioned: true


# report_svr:

report_svr_pred_vs_real:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/svr/pred_vs_real.png
  versioned: true

report_svr_residual_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/svr/residual_plot.png
  versioned: true

report_svr_qq_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/svr/qq_plot.png
  versioned: true 


# report_decision_tree_regression:

report_decision_tree_pred_vs_real:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/decision_tree/pred_vs_real.png
  versioned: true

report_decision_tree_residual_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/decision_tree/residual_plot.png
  versioned: true 

report_decision_tree_qq_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/decision_tree/qq_plot.png
  versioned: true

# report_random_forest_regression:

report_random_forest_pred_vs_real:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/random_forest/pred_vs_real.png
  versioned: true

report_random_forest_residual_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/random_forest/residual_plot.png
  versioned: true

report_random_forest_qq_plot:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/report_regression/random_forest/qq_plot.png
  versioned: true



# ============================


# Se analizan resultados del modelo
# Se comparan métricas
# Se visualizan patrones
# Se presentan conclusiones

# Ejemplos típicos:
# Matriz de confusión
# Curva ROC
# Comparación de accuracy entre modelos

# Generar:

# - Archivos CSV
# - Gráficos (PNG)
# - Reportes HTML
# - Tablas consolidadas


# ============================
# Reportes de clasificacion
# ============================


# ============================
# Reporte final, comparacion de modelos regresion y clasificacion
# ============================

# report comparación mejor modelo regresion:

metris_all_models_regression:
  type: pandas.CSVDataset
  filepath: data/08_reporting/report_regression/metris_all_models_regression.csv
  versioned: true

Reporte_mejor_metrica_modelo_regresion:
  type: pandas.CSVDataset
  filepath: data/08_reporting/report_regression/Reporte_mejor_metrica_modelo_regresion.csv
  versioned: true  

# report comparación mejor modelo clasificacion:

metris_all_models_clasificacion:
  type: pandas.CSVDataset
  filepath: data/08_reporting/report_classification/metris_all_models_clasificacion.csv
  versioned: true

Reporte_mejor_metrica_modelo_clasificacion:
  type: pandas.CSVDataset
  filepath: data/08_reporting/report_classification/Reporte_mejor_metrica_modelo_clasificacion.csv
  versioned: true

# model_comparison_report: regresion
#  type: pickle.PickleDataset
#  filepath: data/07_model_output/model_comparison_report.pkl

# ============================
#      UNSUPERVISED
# ============================

# Entradas o salidas de las tecnicas no supervizadas
# aplicaremos tecnicas no supervizadas para limpiar,
# reducir dimensiones y agregar nuevas columnas con clustering. 

#  ============================
# Estas tecnicas no supervizadas se aplicaran en el dataset de entrada
# model_input_table, y generaran 3 nuevos datasets 
# clean_dataset > clustered_dataset y unsupervised_processed_dataset. En la que esta ultima sera la nueva base para los modelos supervisados .
# ============================

# Luego de hacer el pipeline padre unsupervised_learning, configurar el pipeline registry, los submodulos pipelines y sus parameters
# ahora hay que hacer que las tecnicas de aprendizaje no supervizado afecten nuestro dataset.

# Pipeline Submodulo anomaly_detection.

clean_dataset:
  type: pandas.ParquetDataset
  filepath: data/04_feature/clean_dataset.parquet

# Ver las salidas de los clusters y reduccion 

# Pipeline Submodulo clustering.

clustered_dataset:
  type: pandas.ParquetDataset
  filepath: data/04_feature/clustered_dataset.parquet

# Pipeline Submodulo dimensionality_reduction.

pca_output:
  type: pandas.ParquetDataset
  filepath: data/04_feature/pca_output.parquet  

unsupervised_processed_dataset:
  type: pandas.ParquetDataset
  filepath: data/04_feature/unsupervised_processed_dataset.parquet


# regression_dvc_paths:
#  type: pickle.PickleDataset
#  filepath: data/07_model_output/regression_dvc_paths.pkl

# classification_dvc_paths:
#  type: pickle.PickleDataset
#  filepath: data/07_model_output/classification_dvc_paths.pkl
